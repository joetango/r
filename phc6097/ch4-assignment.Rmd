---
title: "Chapter 4 Assignment"
author: "Joe Dickerson"
date: "2025-09-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE}

library(ISLR2)
data(Weekly)
library(tidyverse)

```

Question 13.

a. 

When looking at the scatterplot matrices with the pairs() function, the most notable pattern is between Year and Volume. Producing a scatterplot of those two variables shows the volume increase as the years increase. This is not unexpected based on an understanding of how the S&P tends to grow with the economy. 

```{r}

summary(Weekly)
pairs(Weekly)
cor(Weekly[,-9])

Weekly %>% 
  ggplot(aes(x = Year, y = Volume)) +
  geom_point()

```

b.

The summary output of the model shows only Lag2 has statistical significance with a p-value of 0.0296.

```{r}

glmod <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, family = binomial, data = Weekly)

summary(glmod)

```

c.

The diagonals indicate the correct predictions, so there are (557 + 54) correct predictions. 

nrow(Weekly) = 1089

611 / 1089 = 0.5611

This can be confirmed using mean().

```{r}

## Creating a prediction table

glm.probs <- predict(glmod, type = "response")
glm.probs[1:10]

contrasts(Weekly$Direction)

## table(glmod, Weekly$Direction)

glm.pred <- rep("Down", nrow(Weekly))
glm.pred[glm.probs > 0.5] = "Up"

summary(glm.pred)

## Producing the confusion matrix
table(glm.pred, Weekly$Direction)

611 / nrow(Weekly)

mean(glm.pred == Weekly$Direction)


```

d. 

Using the mean() function we determine the correct predictions of the held out data to be 0.375.

```{r}

train <- (Weekly$Year < 2009)

weekly.2009 <- Weekly[!train,]

direction.2009 <- Weekly$Direction[!train]

glmod2 <- glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train) 
glm.probs2 <- predict(glmod2, weekly.2009, type = "response")

glm.pred2 <- rep("Down", nrow(weekly.2009))

glm.pred2[glm.probs2 > 0.5] <- "Up"

table(glm.pred2, direction.2009)

mean(glm.pred2 == direction.2009)

mean(glm.pred2 != direction.2009)

```

e.

We repeat the process with LDA, and the fraction of correct predictions is 62.5%:

```{r}

library(MASS)

lda.fit <- lda(Direction ~ Lag2, data = Weekly, subset = train)

summary(lda.fit)

lda.pred <- predict(lda.fit, weekly.2009)
names(lda.pred)

lda.class <- lda.pred$class

table(lda.class, direction.2009)

mean(lda.class == direction.2009)

```

f. 

We repeat the process for QDA, and the fraction of correct predictions is 0.587:

```{r}

qda.fit <- qda(Direction ~ Lag2, data = Weekly, subset = train)

qda.class <- predict(qda.fit, weekly.2009)$class

table(qda.class, direction.2009)

mean(qda.class == direction.2009)

```

g.

We repeat the process for KNN with K=1 and get 0.5 as the fraction of correct predictions:

```{r}

library(class)

train.X <- as.matrix(Weekly$Lag2[train])
test.X <- as.matrix(Weekly$Lag2[!train])
train.Direction <- Weekly$Direction[train]

knn.pred <- knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, direction.2009)

mean(knn.pred == direction.2009) 

```

h.

We repeat the for naive Bayes and get 0.5865 as the fraction of correct predictions:

```{r}

library(e1071)

nb.fit <- naiveBayes(Direction ~ Lag2, data = Weekly, subset = train)

nb.class <- predict(nb.fit, weekly.2009)

table(nb.class, direction.2009)

mean(nb.class == direction.2009)

```

i.

It appears the LDA method provides the best results as it had a fraction of correct predictions at 62.5%, the highest percentage of the various methods. However, further testing may be required to determine this for certain.

j.

The confusion matrix in the model that includes both Lag1 and Volume with Lag2 is similar to the confusion matrix that contains Lag2 alone. The KNN model is less effective with these additional predictors and K set to 3.

```{r}

glmod2 <- glm(Direction ~ Lag2 + Volume, family = binomial, data = Weekly)

glmod3 <- glm(Direction ~ Lag1 + Lag2 + Volume, family = binomial, data = Weekly)


glm.probs3 <- predict(glmod3, type = "response")
glm.probs3[1:10]

contrasts(Weekly$Direction)


glm.pred3 <- rep("Down", nrow(Weekly))
glm.pred3[glm.probs3 > 0.5] = "Up"

summary(glm.pred3)


table(glm.pred3, Weekly$Direction)

611 / nrow(Weekly)

mean(glm.pred3 == Weekly$Direction)


#### 


glmod4 <- glm(Direction ~ Lag1 + Lag2 + Volume, data = Weekly, family = binomial, subset = train) 

glm.probs4 <- predict(glmod4, weekly.2009, type = "response")

glm.pred4 <- rep("Down", nrow(weekly.2009))

glm.pred4[glm.probs4 > 0.5] <- "Up"

table(glm.pred4, direction.2009)

mean(glm.pred4 == direction.2009)

mean(glm.pred4 != direction.2009)

library(class)

train.X2 <- cbind(Weekly$Lag1, Weekly$Lag2, Weekly$Volume)[train,]
test.X2 <- cbind(Weekly$Lag1, Weekly$Lag2, Weekly$Volume)[!train,]
train.Direction <- Weekly$Direction[train]

knn.pred <- knn(train.X2, test.X2, train.Direction, k = 3)

table(knn.pred, direction.2009)

mean(knn.pred == direction.2009) 

```
