---
title: "PHC6097 Exam 1"
author: "Joe Dickerson"
date: "2025-11-09"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}

## packages
library(ISLR2)
library(glmnet)
library(class)
library(tidyverse)
library(boot)
library(splines)
library(gam)

```

Question 3.


```{r, warning=FALSE, message=FALSE}

x.1 <- c(3, 2, 4, 1, 2, 4, 4)
x.2 <- c(4, 2, 4, 4, 1, 3, 1)
y <- c("Red", "Red", "Red", "Red", "Blue", "Blue", "Blue")

plot(x.1, x.2, col = y, ylim = c(0, 6), type = "p", pch = 19)
grid(col = "gray")
abline(-0.5, 1)
abline(-1, 1, lty = 4)
abline(0, 1, lty = 4)

## hyperplane that is not the optimally separating hyperplane:

plot(x.1, x.2, col = y, ylim = c(0, 6), type = "p", pch = 19)
grid(col = "gray")
abline(-0.8, 1)
abline(-1, 1, lty = 4)
abline(-0, 1, lty = 4)

## additional point added to plot

plot(x.1, x.2, col = y, ylim = c(0, 6), type = "p", pch = 19)
points(5, col = "Blue", pch = 19)
grid(col = "gray")

```

Question 5.

1. Fit a logistic regression model that uses income and balance to predict default, and use the validation set approach to estimate the test error of this model. Comment on the results obtained.

Both income and balance are statistically significant in the logistic regression model. The test error found with the validation set approach is 0.021. 

```{r, warning=FALSE, message=FALSE}

data(Default)
set.seed(1)

## adding a column with a numeric response
Default$default.clean <- ifelse(Default$default == "Yes", 1, 0) 

train <- sample(1:nrow(Default), nrow(Default)/2)
test <- -train


glm.mod <- glm(default.clean ~ income + balance, data = Default, family = "binomial", subset = train)

summary(glm.mod)

mean((Default$default.clean - predict(glm.mod, Default, type = "response"))[test]^2) 

## checking test error
glm.pred <- predict(glm.mod, Default[test, ], type = "response")
mean((glm.pred - Default$default.clean[test])^2)

```

2. For the same model, please use the LOOCV approach to obtain the LOOCV estimate of the test error of this model. Comment on the results obtained.

The test error with the LOOCV approach is 0.021, the same as the validation set approach. 

```{r, warning=FALSE, message=FALSE}

set.seed(1)

glm.mod2 <- glm(default ~ income + balance, data = Default, family = "binomial")

cv.err <- cv.glm(Default, glm.mod2) ## will process for a few minutes with many observations

round(cv.err$delta, 3)

```

3. The test error with the cross-validation approach is 0.021, the same as the previous parts.

```{r, warning=FALSE, message=FALSE}

set.seed(1)

glm.mod3 <- glm(default ~ income + balance, data = Default, family = "binomial")

cv.err3 <- cv.glm(Default, glm.mod3, K = 10)

round(cv.err3$delta, 3)

```

Question 7.

In this question, we will predict the number of applications received using
the other variables in the College data set.

1. Split the data set into a training set and a test set (½ as training and ½ as testing by setting the seed as 1. Fit a linear model using least squares on the training set, and report the test error obtained.

The test error is 1,135,758.


```{r, warning=FALSE, message=FALSE}

data(College)

set.seed(1)

train <- sample(1:nrow(College), nrow(College)/2)
test <- -train
y.test <- College$Apps[test]

lmod <- lm(Apps ~ ., data = College, subset = train)

lmodpred <- predict(lmod, College[test, ])

mean((lmodpred - y.test)^2)

```

2. Fit a ridge regression model on the training set, with λ chosen by cross-validation (Hint: the cross-validation process should be conducted on the training set). Report the test error obtained.

The test error is 976,262, which is lower than the test error for the linear regression model. Lambda is determined to be 405.84

```{r, warning=FALSE, message=FALSE}


set.seed(1)

x <- model.matrix(College$Apps ~ ., data = College)[, -1]
x.train <- x[train, ]
y <- College$Apps
y.train <- y[train]


ridge.mod <- glmnet(x.train, y.train, alpha = 0)

cv.ridge.mod <- cv.glmnet(x.train, y.train, alpha = 0)

lambda <- cv.ridge.mod$lambda.min

lambda

r.pred <- predict(ridge.mod, s = lambda, newx = x[test, ])

mean((r.pred - y.test)^2)

```


3. Fit a lasso model on the training set, with λ chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates.

The test error is 1,115,901, which is lower than the linear regression model, but higher than the ridge regression model. There are 17 non-zero coefficients. Lambda is determined to be 1.973.

```{r, warning=FALSE, message=FALSE}

set.seed(1)

lasso.mod <- glmnet(x.train, y.train, alpha = 1)

cv.lasso.mod <- cv.glmnet(x.train, y.train, alpha = 1)

lasso.lambda <- cv.lasso.mod$lambda.min

lasso.lambda

l.pred <- predict(lasso.mod, s = lasso.lambda, newx = x[test, ])

mean((l.pred - y.test)^2)

l.coefs <- predict(lasso.mod, type = "coefficients", s = lasso.lambda)[1:17, ]

length(l.coefs[l.coefs != 0])

```


4. Fit a K-nearest neighbors (KNN) model on the training set, with K chosen by cross-validation. Report the test error obtained, along with the value of K selected by cross-validation

We use cross validation to determine the optimal K value, which in this case is 3. The test error is 18,238,830, which is remarkably higher than the previous methods used. 

```{r, warning=FALSE, message=FALSE}

set.seed(1)

k.vals <- 1:10
knn.errs <- rep(0, length(k.vals))

for (i in k.vals) {
  knn.pred <- knn(train = x.train, test = x[test, ], cl = y.train, k = i)
  knn.pred <- as.numeric(knn.pred)
  knn.errs[i] <- mean((knn.pred - y.test)^2)
}

k.vals[which.min(knn.errs)]

knn.pred <- knn(x.train, x.train[test,], y.train, k = 3)

mean((as.numeric(knn.pred) - y.test)^2)

```


#####################################################################

Question 9.

In this question, you will further analyze the Wage data set considered throughout this chapter. Please set the random seed as 1 for the analysis.

1. Perform polynomial regression to predict wage using age. Use cross-validation to select the optimal degree d for the polynomial. What degree was chosen, and how does this compare to the results of hypothesis testing using ANOVA? Make a plot of the resulting polynomial fit to the data.

After performing cross-validation, it appears a polynomial with degree = 4 is the optimal choice. Performing an ANOVA, we find similar results, with the degree 4 polynomial being the highest degree with statistical significance, though degree 4 is just barely significant with a p-value of 0.051, so it may be better to use degree 3 as it is easier to contextualize and to not overfit the data. We plot the degree 4 polynomial to further examine.

```{r, warning=FALSE, message=FALSE}

data(Wage)
set.seed(1)

cv.error <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(wage ~ poly(age, i), data = Wage)
  cv.error[i] <- cv.glm(Wage, glm.fit, K = 10)$delta[1] # K = 10, computer hangs up otherwise
}

plot(cv.error, type = "l")
points(cv.error, pch = 19)

##ANOVA
fit.1 <- lm(wage ~ age, data = Wage)
fit.2 <- lm(wage ~ poly(age, 2), data = Wage)
fit.3 <- lm(wage ~ poly(age, 3), data = Wage)
fit.4 <- lm(wage ~ poly(age, 4), data = Wage)
fit.5 <- lm(wage ~ poly(age, 5), data = Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)

## Plot
plot(wage ~ age, data = Wage, col = "grey", main = "Wage vs. Age With Degree 4 Polynomial Fit")
agelims <- range(Wage$age)
age.grid <- seq(from = agelims[1], to  = agelims[2])
poly.fit <- lm(wage ~ poly(age, 4), data = Wage)
preds <- predict(poly.fit, newdata = list(age = age.grid))
lines(age.grid, preds, col = "cyan", lwd = 3)

```



2. Fit a step function to predict wage using age, and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained.

It appears that 8 is the optimal number of cuts. We check this graphically. Then we plot the fit.

```{r, warning=FALSE, message=FALSE}

cv.error2 <- rep(0, 10)

for (i in 2:10){
  Wage$age.cut <- cut(Wage$age, i)
  step.fit <- glm(wage ~ age.cut, data = Wage)
  cv.error2[i] <- cv.glm(Wage, step.fit, K = 10)$delta[1]
}

plot(cv.error2, ylab = "Test Error", xlab = "Cuts", type = "l")
points(cv.error2, pch = 19)

plot(wage ~ age, data = Wage, col = "grey", main = "Step-function fit")
agelims <- range(Wage$age)
age.grid2 <- seq(from = agelims[1], to = agelims[2])
fit2 <- glm(wage ~ cut(age, 8), data = Wage)
preds2 <- predict(fit2, data.frame(age = age.grid2))
lines(age.grid2, preds2, col = "cyan", lwd = 3)


```

3. Fit a natural cubic spline to predict wage using age.

We fit a natural cubic spline and create a plot with the prediction. 

```{r, warning=FALSE, message=FALSE}

spline.fit <- lm(wage ~ ns(age, df = 4), data = Wage)

spline.pred <- predict(spline.fit, newdata = list(age = age.grid), se = T)

plot(wage ~ age, data = Wage, col = "grey", main = "Natural Cubic Spline Fit")
lines(age.grid, spline.pred$fit, col = "cyan", lwd = 2)

```

4. Use a GAM model to predict wage using age, education, and marital status.

```{r}

gam1 <- gam(wage ~ s(age, 5) + education + maritl, data = Wage)

gam.preds <- predict(gam1, newdata = Wage)

par(mfrow = c(1, 3))
plot(gam1, se = TRUE, col = "green")

plot(Wage$wage, gam.preds, ylab = "Predicted Wage", xlab = "Observed Wage", col = "darkgrey")
abline(0, 1, col = "cyan", lwd = 3)

```


