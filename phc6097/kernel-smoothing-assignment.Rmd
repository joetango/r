---
title: "Kernel Smoothing Assignment"
author: "Joe Dickerson"
date: "2025-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Question 1

  1. True
  
  2. True
  
  3. False
  
  4. True
  
  5. True

Question 2 

  C. Gaussian Kernel
  
Question 3.

Given:

x0 = 5, x1 = 4.9, x2 = 3, y1 = 1, y2 = 2


```{r}

## Computing kernel weights:

exp <- exp(1)

fnc <- function(x, x0, a){
  exp(-((x - x0)^2) / (2*a^2))
}

fnc(4.9, 5, .5) ## 0.980200
fnc(3, 5, .5)   ## 0.000335

```

L(B0, B1) = 2 sigma i=1 ki(yi - (B0 + B1xi))^2

L(B0, B1) = k1(y1 - (B0 +B1x1))^2 + k2(y2 - (B0 + b1x2))^2

Loss function:

L(B0, B1) = 0.9802(1 - (B0 + B1 ⋅ 4.9))^2 + 0.00036(2 - (B0 + B1 ⋅ 3))^2

#############

Question 4.

Weighted least squares solution for local linear regression:

(sum i=1 to N) Kgamma(x0, xi)[yi - alpha(x0) - B(x0)xi]^2

Vector valued function is defined: b(x)^T = (1, x)

B is defined as N x 2 regression matrix with i'th row b(xi)^T,

and W(x0) the N x N diagonal matrix with i'th diagonal element Kgamma(x0, xi)


f-hat(x0) = b(x0)^T(B^T * W(x0)B)^-1B^T * W(x0)y

equals

(sum i=1 to N) li(x0)yi

Because N is respective to our i'th y-value, 

(sum i=1 to N) li(x0) = 1 such that (sum i=1 to N) = yi


Question 5.

```{r, echo=FALSE, warning=FALSE, error=FALSE}

## WORKSPACE

## Local linear fit (error?)

LLR <- function(x, X, Y, h, K = dnorm) {
  d <- sapply(x, function(xi) {
  Kx <- K((X - xi) / h) / h  
  D <- cbind(1, X)  
  W <- diag(Kx)
  beta <- solve(t(D) %*% W %*% D) %*% t(D) %*% W %*% Y  
    return(c(1, xi) %*% beta)
  })
}

```

```{r}

library(dslabs)
library(MASS)

data(polls_2008)

## k-NN 

kNN <- function(x, X, Y, h) {
  n <- length(X)
  Kx <- sapply(x, function(xi) {
  d <- abs(X - xi)
  ind <- order(d)[1:h]
  mean(Y[ind])
  })
}

par(mfrow = c(1, 3))

plot(polls_2008$day, polls_2008$margin, main = "k-NN K = .5", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), kNN(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = .5), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "k-NN K = 2", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), kNN(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 2), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "k-NN K = 4", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), kNN(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 4), col = 2)

## Nadaraya-Watson

mNW <- function(x, X, Y, h, K = dnorm) {
  Kx <- sapply(X, function(Xi) K((x - Xi) / h) / h)
  W <- Kx / rowSums(Kx) 
  drop(W %*% Y)
}

par(mfrow = c(1, 3))

plot(polls_2008$day, polls_2008$margin, main = "Nadaraya-Watson K = .5", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), mNW(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = .5), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "Nadaraya-Watson K = 2", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), mNW(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 2), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "Nadaraya-Watson K = 4", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), mNW(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 4), col = 2)

par(mfrow = c(1, 3))

plot(polls_2008$day, polls_2008$margin, main = "Local Linear Fit K = .5", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), LLR(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = .5), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "Local Linear Fit K = 2", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), LLR(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 2), col = 2)

plot(polls_2008$day, polls_2008$margin, main = "Local Linear Fit K = 4", xlab = "Day", ylab = "Margin")
lines(seq(-155, -1, 1), LLR(x = seq(-155, -1, 1), X = polls_2008$day, Y = polls_2008$margin, h = 4), col = 2)

```

